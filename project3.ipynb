{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAaw5yXfKrxY"
   },
   "source": [
    "# POS Tagging via Bi-directional LSTM-CNNs-CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQnkXf7bKrxb"
   },
   "source": [
    "In this document, I will show you how to implement a state of the art [Bi-directional LSTM-CNN-CRF architecture](http://www.aclweb.org/anthology/P16-1101) for POS tagging using pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t5cci7xKrxc"
   },
   "source": [
    "The agenda of this implementation is as follows:\n",
    "1. Processing data samples using two pytorch data primitives: [Dataset & dataloader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "2. Replace the randomly initialized embeddings with pre-trained word embeddings: [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "3. Build up LSTM-CNNs-CRF model, this includes:\n",
    "    1. character CNN encoder for char level embeddings\n",
    "    2. randomly initialized word embeddings or pretrained word embeddings\n",
    "    3. charCNN layer\n",
    "    4. biLSTM layer\n",
    "    5. CRF layer\n",
    "4. Training/validating/testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GidfjPA9FsdH",
    "outputId": "6a2e6299-9c7f-474f-d120-a5b9810bdea9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/xiyaguan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axNrvuJLKrxf"
   },
   "source": [
    "## I. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "pGmd2gcVGg2W"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.002\n",
    "DROPOUT = 0.2\n",
    "EMBED_DIM = 50  # input word embedding dimension\n",
    "CHAR_EMBED_DIM = 50  # = num_output_channel (number of kernels or filters) of charCNN: charator embedding dimension \n",
    "HIDDEN_DIM = 50  # The number of features in the hidden state h in LSTM layer\n",
    "NUM_LAYERS = 1  # number of LSTM layers  \n",
    "BIDIRECTIONAL = True  # If True, becomes a bidirectional LSTM\n",
    "KERNEL_SIZE = 2  # Size of the convolving kernel (number of chars to apply a single convolution)\n",
    "\n",
    "# GPU setting\n",
    "SEED = 1334\n",
    "DEVICE_ID = 0\n",
    "\n",
    "# padding and unknown symbols and indicis for token\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "UNK = '<unk>'\n",
    "PAD = '<pad>'\n",
    "\n",
    "# padding and unknown symbols and indicis for charactors\n",
    "CHAR_PAD_IDX = 0\n",
    "CHAR_UNK_IDX = 1\n",
    "CHAR_UNK = '<char_unk>'\n",
    "CHAR_PAD = '<char_PAD>'\n",
    "\n",
    "# beging of sentence tag and end of sentence tag\n",
    "BOS = '<bos>' # CRF\n",
    "EOS = '<eos>' # CRF\n",
    "\n",
    "# hyperparameter for implementing char embedding using charCNN\n",
    "# for each words, we will do pad or trauncate \n",
    "# to convert the original word into a WORD_LEN letters word.\n",
    "WORD_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXVQxxCkGkTW",
    "outputId": "8d47bf00-5f1c-4a17-bc21-0383328d3124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{DEVICE_ID}\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "YMxCB_wUGmEL"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrudG93BJsGA"
   },
   "source": [
    "## II. Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "5SAAvljeJyym"
   },
   "outputs": [],
   "source": [
    "def read_in_gold_data(filename):\n",
    "    \"\"\"Read in the labeled gold data into a list\"\"\"\n",
    "    dataset = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            tuples = [tup.split('_') for tup in line.split()]\n",
    "            tokens = [tup[0].lower() for tup in tuples]\n",
    "            tags = [tup[1] for tup in tuples]\n",
    "            dataset.append((tokens, tags))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_IsRdA7moz3",
    "outputId": "a4a1ac0a-2f9e-48af-9198-989ff9ba2eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39832\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# train_filepath = os.path.join(os.getcwd(), \"train/train.tagged\")\n",
    "# train_filepath = \"/content/drive/MyDrive/PA3_Starter_code/train/train.tagged\"\n",
    "# train_filepath = \"/content/drive/MyDrive/PA3_Starter_code/train/ptb_02-21.tagged\"\n",
    "train_filepath = os.path.join(os.getcwd(), \"train/ptb_02-21.tagged\")\n",
    "training = read_in_gold_data(train_filepath)\n",
    "print(len(training))\n",
    "dev_filepath = os.path.join(os.getcwd(), \"dev/ptb_22.tagged\")\n",
    "# dev_filepath = \"/content/drive/MyDrive/PA3_Starter_code/dev/ptb_22.tagged\"\n",
    "dev = read_in_gold_data(dev_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmbbElBDK8C2"
   },
   "source": [
    "## III. Build up tokens/tags/chars vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "j6NcPIOcHLh3"
   },
   "outputs": [],
   "source": [
    "tokens, tags, chars = set(), set(), set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaC1ktG7NGFq",
    "outputId": "5bfebcd3-49d7-4bda-aba3-27256c86f9ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4634)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lens = []\n",
    "for sent in training:\n",
    "    tokens.update(sent[0])\n",
    "    tags.update(sent[1])\n",
    "    for word in sent[0]:\n",
    "        chars.update(word)\n",
    "        word_lens.append(len(word))\n",
    "a = torch.tensor(word_lens)\n",
    "torch.mean(a.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "NXk5DAVwO4We"
   },
   "outputs": [],
   "source": [
    "tokens, tags, chars = sorted(tokens), sorted(tags), sorted(chars)\n",
    "# tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "S6t0RRnwPGJT"
   },
   "outputs": [],
   "source": [
    "tokens = [PAD, UNK] + tokens\n",
    "token2idx = {word: i for i, word in enumerate(tokens)}\n",
    "idx2token = {i: word for i, word in enumerate(tokens)}\n",
    "token_vocab = (token2idx, idx2token)\n",
    "# len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZgHjrHWSxDj",
    "outputId": "cefa4d27-1d5c-47d6-ae38-3322015225d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '<eos>', '#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
     ]
    }
   ],
   "source": [
    "tags = [BOS, EOS] + tags\n",
    "tag2idx = {word: i for i, word in enumerate(tags)}\n",
    "idx2tag = {i: word for i, word in enumerate(tags)}\n",
    "tag_vocab = (tag2idx, idx2tag)\n",
    "num_tags = len(tags)\n",
    "TAG_PAD_IDX = num_tags\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "Fag5RAgBKrxm"
   },
   "outputs": [],
   "source": [
    "chars = [CHAR_PAD, CHAR_UNK] + chars\n",
    "char2idx = {char: i for i, char in enumerate(chars)}\n",
    "idx2char = {i: char for i, char in enumerate(chars)}\n",
    "char_vocab = (char2idx, idx2char)\n",
    "# chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1Vxn7HboTR6"
   },
   "source": [
    "## IV. Creating a Custom Dataset and Dataloader\n",
    "1. Customize Dataset\n",
    "2. Determine bucket boundaries\n",
    "3. Customize batch sampler\n",
    "4. Customize collate function\n",
    "5. Customize Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-iMhgDsKrxn"
   },
   "source": [
    "### 1. Customize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "GWs7NJtNkKxt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "Ytm9XTuikNaz"
   },
   "outputs": [],
   "source": [
    "class POStagging(Dataset):\n",
    "    def __init__(self, data, token2idx, tag2idx):\n",
    "        self.data = data\n",
    "        self.token2idx = token2idx\n",
    "        self.tag2idx = tag2idx\n",
    "\n",
    "    def featurize(self, tokens, tags):\n",
    "        normalized_tokens = [x if x in self.token2idx else UNK for x in tokens]\n",
    "        featurized_tokens = [self.token2idx[x] for x in normalized_tokens]\n",
    "        featurized_tags = [self.tag2idx[x] for x in tags]\n",
    "        return featurized_tokens, featurized_tags\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, tags = self.data[idx]\n",
    "        featurized_tokens, featurized_tags = self.featurize(tokens, tags)\n",
    "\n",
    "        x = torch.tensor(featurized_tokens, dtype=torch.int64)\n",
    "        y = torch.tensor(featurized_tags, dtype=torch.int64)\n",
    "        return x, y, tokens, tags\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "MExNW4STrF2d"
   },
   "outputs": [],
   "source": [
    "training_dataset = POStagging(training, token2idx, tag2idx)\n",
    "dev_dataset = POStagging(dev, token2idx, tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLOkr2_iTIDu"
   },
   "source": [
    "### 2. Choosing bucket boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "aK-cDYL2TO9l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R62q979TWRr8",
    "outputId": "26565aad-0514-48e7-850b-d6ac4acad0e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23.850873669411527, 141)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.array([len(x[0]) for x in training])\n",
    "np.min(lens), np.mean(lens), np.max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "RFNR2pZOWeYd"
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.grid(True)\n",
    "# plt.hist(lens, bins=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "ZHpW3nU0Wahm"
   },
   "outputs": [],
   "source": [
    "# inclusive for endpoints\n",
    "# bucket ranges: [:10], [10:20], [20:30], [30:40], [40:60], [60:]\n",
    "buckets = [10, 20, 30, 40, 60, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "NUuJ_WyGXrXj"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[100, 25])\n",
    "# plt.subplot(121)\n",
    "# plt.hist(lens, bins=10)\n",
    "# plt.grid(True)\n",
    "# plt.title('Distribution of Lengths')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "as-qalBSZjrp"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[100, 25])\n",
    "# plt.subplot(122)\n",
    "# plt.hist(lens, bins=[1]+buckets+[100], align='mid')\n",
    "# plt.grid(True)\n",
    "# plt.title('Bucketed Lengths')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUJFDdCNZ13E"
   },
   "source": [
    "### 3. Customize batch sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "MqrDN_Khfvey"
   },
   "outputs": [],
   "source": [
    "def batchify(iterable, n):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx: min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "adVmo-JMZ5GJ"
   },
   "outputs": [],
   "source": [
    "class CustomBucketSampler:\n",
    "    def __init__(self, dataset, buckets, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.buckets = buckets  \n",
    "        self.num_buckets = len(buckets) + 1  # 6\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # 1. collect lengths (and corresponding ids) of all data instances\n",
    "        idx_lens = [(i, len(x[0])) for i, x in enumerate(self.dataset)]\n",
    "        \n",
    "        # 2. sort by lengths\n",
    "        idx_lens = sorted(idx_lens, key=lambda x:x[1])\n",
    "        \n",
    "        # 3. create empty buckets\n",
    "        buckets = [[] for _ in range(self.num_buckets)]\n",
    "        \n",
    "        # 4. assign data to appropriate buckets\n",
    "        for i, l in idx_lens:\n",
    "            for j, bucket_limit in enumerate(self.buckets):\n",
    "                if l <= bucket_limit: # if length falls within a certain boundary\n",
    "                    buckets[j].append(i)\n",
    "                    break\n",
    "            # for data whose length is greater than the max boundary (9), assign to last bucket\n",
    "            if l > bucket_limit: # `bucket_limit` guaranteed to be 9\n",
    "                buckets[-1].append(i)\n",
    "                \n",
    "        # make sure the numbers match up\n",
    "        assert sum([len(x) for x in buckets]) == len(self.dataset)\n",
    "        \n",
    "        # 5. create batches in each bucket while shuffling\n",
    "        batches = []\n",
    "        for bucket in buckets: \n",
    "            random.shuffle(bucket)\n",
    "            for batch in batchify(bucket, self.batch_size):\n",
    "                batches.append(batch)\n",
    "\n",
    "        # 6. shuffle batches and finally yield\n",
    "        random.shuffle(batches)\n",
    "        for batch in batches:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "4bta-P3MgOQU"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_sampler = CustomBucketSampler(training, buckets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "z-FZJSoNiSeP"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLphb5QbKrxq"
   },
   "source": [
    "### 4. Customize collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "RBKyAcR3iwjj"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):  \n",
    "#     print(batch[0][0])\n",
    "#     print(batch[0][1])\n",
    "#     print(batch[0][2])\n",
    "#     print(batch[0][3])\n",
    "    featurized_tokens, featurized_tags, row_tokens, row_tags = zip(*batch)\n",
    "#     print(f\"featurized_tokens:{featurized_tokens}\")\n",
    "#     print(f\"featurized_tags:{featurized_tags}\")\n",
    "#     print(f\"row_tokens:{type(row_tokens)}\")\n",
    "#     print(f\"row_tags:{row_tags}\")\n",
    "    lens = [len(x) for x in featurized_tokens]\n",
    "#     print(f\"lens:{lens}\")\n",
    "    tokens = pad_sequence(featurized_tokens, batch_first=True, padding_value=PAD_IDX)\n",
    "    tags = pad_sequence(featurized_tags, batch_first=True, padding_value=TAG_PAD_IDX)\n",
    "    return tokens, tags, row_tokens, row_tags, torch.tensor(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKnZ1ANrjjDx"
   },
   "source": [
    "### 5. Customize Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "aFELr76qjm_s"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "Fi5Oc3OVjsOd"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(training_dataset, collate_fn=collate_fn, batch_sampler=train_sampler)\n",
    "dev_dl = DataLoader(dev_dataset, batch_size=len(dev_dataset), collate_fn=collate_fn)\n",
    "# tokens, tags, row_tokens, row_tags, lens = next(iter(dev_dl))\n",
    "# print(tokens.shape)\n",
    "# print(tags.shape)\n",
    "# print(lens.shape)\n",
    "# print(len(row_tokens))\n",
    "# x, y, tokens, tags\n",
    "# for i, batch in enumerate(train_dl):\n",
    "#     print(batch)\n",
    "# #     print(f\"featurized_tokens:{batch[0][0]}\")\n",
    "# #     print(f\"featurized_tags:{batch[0][1]}\")\n",
    "# #     print(f\"row_tokens:{batch[0][2]}\")\n",
    "# #     print(f\"row_tags:{batch[0][3]}\")\n",
    "# #     print(f\"lens:{batch[0][4]}\")\n",
    "#     if i == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiqoj5GeKrxr"
   },
   "source": [
    "## V. Set up pretrained word embeddings -- Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "vC8pkJtxKrxr"
   },
   "outputs": [],
   "source": [
    "## Code the read in pre-trained word embeddings\n",
    "def glove2dict(glove_path,emb_dim=50):\n",
    "    \"\"\"Read in glove embeddings and create a dictionary\"\"\"\n",
    "    glove_dict = {}\n",
    "    if emb_dim == 50:\n",
    "        fname= \"glove.6B.50d.txt\"\n",
    "    elif emb_dim == 100:\n",
    "        fname=\"glove.6B.100d.txt\"\n",
    "    elif emb_dim == 200:\n",
    "        fname=\"glove.6B.200d.txt\"\n",
    "    elif emb_dim == 300:\n",
    "        fname=\"glove.6B.300d.txt\"\n",
    "    else:\n",
    "        print(\"Inappropriate glove size chosen, using 50\")\n",
    "        fname=\"glove.6B.50d.txt\"\n",
    "    with open(f'{glove_path}/{fname}', 'rb') as f:\n",
    "        for l in f:\n",
    "            line = l.decode().split()\n",
    "            word = line[0]\n",
    "            vect = np.array(line[1:])\n",
    "            glove_dict[word] = vect\n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "mzqBkgmAKrxs"
   },
   "outputs": [],
   "source": [
    "def create_glove_embeddings(glove_path, token2idx, emb_dim=50):\n",
    "    \"\"\"create the glove embeddings for a target dictionary\"\"\"\n",
    "    glove = glove2dict(glove_path, emb_dim)\n",
    "    matrix_len = len(token2idx) \n",
    "  \n",
    "    weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "    pad_weight = np.zeros((1, emb_dim))\n",
    "    words_not_found = 0\n",
    "    \n",
    "    for word, idx in token2idx.items():\n",
    "        if word == PAD:\n",
    "            weights_matrix[idx] = pad_weight\n",
    "        \n",
    "        else:\n",
    "            try:\n",
    "                weights_matrix[idx] = glove[word]\n",
    "            except KeyError:\n",
    "                weights_matrix[idx] = np.random.normal(scale=0.6, size=(1, emb_dim))\n",
    "                words_not_found += 1\n",
    "    return torch.from_numpy(weights_matrix).float(), words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inikF1TAKrxs",
    "outputId": "39333867-4c2d-41d8-ecd1-4e145b6817bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words not found in glove:5749\n"
     ]
    }
   ],
   "source": [
    "glove_path = os.path.join(os.getcwd(), \"embedding\")\n",
    "# glove_path = \"/content/drive/MyDrive/PA3_Starter_code/embedding\"\n",
    "weights_matrix, words_not_found = create_glove_embeddings(glove_path, token2idx, EMBED_DIM)\n",
    "print(f\"words not found in glove:{words_not_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ2bWmo7Krxs"
   },
   "source": [
    "## VI. Build up model\n",
    "1. charCNN layer (customize charCNNEmbeddings)\n",
    "2. biLSTM layer\n",
    "3. CRF layer\n",
    "4. biLSTM_greedy model (without CRF layer)\n",
    "5. biLSTM_CRF model (with CRF layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOwsEmeEKrxs"
   },
   "source": [
    "### 1. charCNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "Pu6Xz3BAKrxs"
   },
   "outputs": [],
   "source": [
    "class CharCNNEmbeddings(nn.Module):\n",
    "    def __init__(self, char_input_dim, char_embed_dim, char_pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(char_input_dim, char_embed_dim, padding_idx=char_pad_idx, device=device)\n",
    "    \n",
    "    def forward(self, x, row_x, lens):\n",
    "        # x.shape: [batch_size, seq_length]\n",
    "        # row_x: list of list of words [I idx(l), idx(o), idx(v), idx(e), 0,0, 0 you], [I hate], []\n",
    "        \n",
    "        \n",
    "        # return shape: [batch_size, seq_length, char_embeddings_dim, word_len]\n",
    "        batch_size, seq_length = x.size()\n",
    "        # input_tensor.shape [batch_size, max_seq_length, WORD_LEN]\n",
    "        input_tensor = torch.zeros(batch_size, seq_length, WORD_LEN, dtype=torch.long)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(lens[i]):\n",
    "                for k, char in enumerate(row_x[i][j][:WORD_LEN]):\n",
    "                    if char in char2idx:\n",
    "                        input_tensor[i, j, k] = char2idx[char]\n",
    "                    else:\n",
    "                        input_tensor[i, j, k] = CHAR_UNK_IDX\n",
    "        char_embeddings_features = self.embeddings(input_tensor)\n",
    "        # [batch_size, max_seq_length, char_embeddings_dim, fixed_word_len=20]\n",
    "        return char_embeddings_features.permute(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "fWCNIQ-QKrxt"
   },
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    def __init__(self, char_input_dim, char_embed_dim, hidden_dim, kernel_size, char_pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = CharCNNEmbeddings(char_input_dim, char_embed_dim, char_pad_idx, device)\n",
    "        self.conv = nn.Conv1d(char_embed_dim, hidden_dim, kernel_size)\n",
    "        \n",
    "    def forward(self, x, row_x, lens):\n",
    "        # [batch_size, seq_length, char_embeddings_dim, word_len]\n",
    "        embeds = self.embedding(x, row_x, lens)\n",
    "        batch_size, seq_length, char_embed_dim, word_len = embeds.size()\n",
    "        \n",
    "        max_pooling_output = torch.zeros(batch_size, seq_length, self.hidden_dim)\n",
    "        for i in range(batch_size):\n",
    "            conv = F.relu(self.conv(embeds[i]))          \n",
    "            conv = F.max_pool1d(conv, conv.shape[-1])\n",
    "            conv = torch.squeeze(conv, -1)            \n",
    "            max_pooling_output[i] = conv\n",
    "            \n",
    "        # char_embeddings_dim, word_len   -> (50, )\n",
    "        return max_pooling_output  # [[batch_size, seq_length, embed_dim]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "C2nuwbl8Krxt"
   },
   "outputs": [],
   "source": [
    "# char_input_dim = len(chars)\n",
    "# char_embed_dim = CHAR_EMBED_DIM\n",
    "# kernel_size = 2\n",
    "# char_pad_idx = CHAR_PAD_IDX\n",
    "# hidden_dim = 50\n",
    "# # emb = CharCNNEmbeddings(char_input_dim, CHAR_EMBED_DIM, CHAR_PAD_IDX)\n",
    "# x = torch.tensor([[2, 3, 4, 0], [2, 5, 0, 0], [2, 6, 3, 4]])\n",
    "# row_x = [['i', 'love', 'you'], ['i', 'what'], ['i', 'dont', 'love', 'you']]\n",
    "# lens = torch.tensor([3, 2, 4])\n",
    "# # emb(x, row_x, lens)\n",
    "# cnn = CharCNN(char_input_dim, char_embed_dim, hidden_dim, kernel_size, char_pad_idx)\n",
    "# cnn(x, row_x, lens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7uhmb5VKrxt"
   },
   "source": [
    "### 2. biLSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "TEd-iniTA88d"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, char_input_dim, output_dim, device, token_pad_idx, char_pad_idx, pretrained_weights):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        1. word_embedding\n",
    "        '''\n",
    "#         if pretrained_weights == None:\n",
    "        self.embedding = nn.Embedding(input_dim, EMBED_DIM, padding_idx=token_pad_idx)\n",
    "#         else:\n",
    "#         print(pretrained_weights.shape)\n",
    "        # self.embedding = nn.Embedding.from_pretrained(pretrained_weights, freeze=True)\n",
    "            \n",
    "        '''\n",
    "        2. char-CNN embedding\n",
    "        '''\n",
    "#         self.charembedding = CharCNN(char_input_dim, CHAR_EMBED_DIM, EMBED_DIM, KERNEL_SIZE, char_pad_idx, device)\n",
    "        self.lstm = nn.LSTM(EMBED_DIM, HIDDEN_DIM, num_layers=NUM_LAYERS, batch_first=True, bidirectional=BIDIRECTIONAL)\n",
    "        self.linear = nn.Linear(HIDDEN_DIM*2 if BIDIRECTIONAL else HIDDEN_DIM, output_dim) # project to vocab space\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.device = device\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        direction_multiplier = 2 if BIDIRECTIONAL else 1\n",
    "        return (torch.randn(direction_multiplier * NUM_LAYERS, batch_size, HIDDEN_DIM, device=self.device), # h0\n",
    "                torch.randn(direction_multiplier * NUM_LAYERS, batch_size, HIDDEN_DIM, device=self.device)) # c0\n",
    "        \n",
    "    def forward(self, x, rows_x, lens):\n",
    "        '''\n",
    "        1. word_embedding\n",
    "        '''\n",
    "        token_embed = self.embedding(x)  # shape: [batch_size, seq_length, emb_dim]\n",
    "        '''\n",
    "        2. char-CNN embedding\n",
    "        '''\n",
    "#         char_embed = self.charembedding(x, rows_x, lens)\n",
    "#         embed = token_embed + char_embed\n",
    "#         embed = torch.cat((token_embed, char_embed), dim=2)\n",
    "        embed = self.embedding(x)\n",
    "        embed = self.dropout(embed)\n",
    "        batch_size = embed.shape[0]\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        outputs, _ = self.lstm(embed, self.hidden)\n",
    "        outputs = self.linear(outputs)\n",
    "        return outputs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0WLU3jJKrxt"
   },
   "source": [
    "### 3. CRF layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "GJBNgr5_Krxu"
   },
   "outputs": [],
   "source": [
    "class CRF(nn.Module):\n",
    "    \"\"\"TODO: Impelement CRF forward, score and viterbi functions\"\"\"\n",
    "    def __init__(self, tgt_vocab, device):\n",
    "        super().__init__()\n",
    "        self.tag2idx, self.idx2tag = tgt_vocab\n",
    "        self.tag_size = len(self.tag2idx)\n",
    "        self.device = device\n",
    "        \n",
    "        # transition matrix\n",
    "        self.start_transitions = nn.Parameter(torch.empty(num_tags, device=self.device))\n",
    "        self.end_transitions = nn.Parameter(torch.empty(num_tags, device=self.device))\n",
    "        self.transitions = nn.Parameter(torch.empty(num_tags, num_tags, device=self.device))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        # print(self.start_transitions.is_cuda)\n",
    "        # print(self.end_transitions.is_cuda)\n",
    "        # print(self.transitions.is_cuda)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
    "    \n",
    "    def forward(self, feats, lens):\n",
    "        emissions = feats.transpose(0, 1)\n",
    "        # print(\"I am here\")\n",
    "        # print(emissions.is_cuda)\n",
    "        seq_length, batch_size = emissions.shape[0], emissions.shape[1]\n",
    "        # build up tag mask\n",
    "        # print(f\"seq_length.is_cuda:{seq_length.is_cuda:}\")\n",
    "        # print(f\"batch_size.is_cuda:{batch_size.is_cuda:}\")\n",
    "        # mask = torch.empty(seq_length, device=self.device)\n",
    "        # torch.arange(seq_length).expand(lens.shape[0], seq_length).cuda() < lens.unsqueeze(1)\n",
    "        # print(lens.unsqueeze(1).is_cuda)\n",
    "        # mask = (torch.arange(seq_length).expand(lens.shape[0], seq_length) < lens.unsqueeze(1)).cuda()\n",
    "        # mask = torch.arange(seq_length).expand(len(lens), seq_length) < lens.unsqueeze(1)\n",
    "        # mask.cuda()\n",
    "        mask = torch.transpose(torch.arange(seq_length).expand(lens.shape[0], seq_length) < lens.unsqueeze(1), 0, 1)\n",
    "        # print(mask)\n",
    "        # print(\"I am here at mask\")\n",
    "        # print(f\"mask.is_cuda{mask.is_cuda}\")\n",
    "        score = self.start_transitions + emissions[0]\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emissions = emissions[i].unsqueeze(1)\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
    "            next_score = torch.logsumexp(next_score, dim=1)\n",
    "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
    "            \n",
    "        score += self.end_transitions\n",
    "        res = torch.logsumexp(score, dim=1)\n",
    "        return res\n",
    "        \n",
    "        \n",
    "    def score(self, feats, tags, lens):\n",
    "        # emissions.shape: [seq_len, batch_size, num_tags]\n",
    "        # tags.shape: [seq_len, batch_size]\n",
    "        # lens.shape: [batch_size, ]\n",
    "        # emissions\n",
    "        emissions = feats.transpose(0, 1)\n",
    "        tags = tags.transpose(0, 1)\n",
    "        seq_length, batch_size = tags.size()\n",
    "        \n",
    "        # build up tag mask\n",
    "        mask = (tags != TAG_PAD_IDX)\n",
    "        # gold tags \n",
    "        tags = tags * mask\n",
    "        \n",
    "        score = self.start_transitions[tags[0]]\n",
    "        score += emissions[0, torch.arange(batch_size), tags[0]]\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            score += self.transitions[tags[i - 1], tags[i]] * mask[i]\n",
    "            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]\n",
    "        \n",
    "        seq_ends = lens - 1\n",
    "        last_tags = tags[seq_ends, torch.arange(batch_size)]\n",
    "        score += self.end_transitions[last_tags]\n",
    "        return score\n",
    "    \n",
    "    def viterbi(self, feats, lens):\n",
    "        emissions = feats.transpose(0, 1)\n",
    "        seq_length, batch_size = emissions.shape[0], emissions.shape[1]\n",
    "        # build up tag mask\n",
    "        # print(torch.arange(seq_length).expand(lens.shape[0], seq_length).cuda().is_cuda)\n",
    "        # print(lens.unsqueeze(1).is_cuda)\n",
    "        mask = torch.transpose(torch.arange(seq_length).expand(lens.shape[0], seq_length) < lens.unsqueeze(1), 0, 1)\n",
    "        \n",
    "        score = self.start_transitions + emissions[0]\n",
    "        history = []\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emission = emissions[i].unsqueeze(1)\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
    "            next_score, indices = next_score.max(dim=1)\n",
    "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
    "            history.append(indices)\n",
    "        \n",
    "        score += self.end_transitions\n",
    "        seq_ends = lens - 1\n",
    "#         seq_ends = mask.long().sum(dim=0) - 1\n",
    "        best_tags_list = []\n",
    "        \n",
    "        for idx in range(batch_size):\n",
    "            # Find the tag which maximizes the score at the last timestep; this is our best tag\n",
    "            # for the last timestep\n",
    "            _, best_last_tag = score[idx].max(dim=0)\n",
    "            best_tags = [best_last_tag.item()]\n",
    "\n",
    "            # We trace back where the best last tag comes from, append that to our best tag\n",
    "            # sequence, and trace it back again, and so on\n",
    "            for hist in reversed(history[:seq_ends[idx]]):\n",
    "                best_last_tag = hist[idx][best_tags[-1]]\n",
    "                best_tags.append(best_last_tag.item())\n",
    "\n",
    "            # Reverse the order because we start from the last timestep\n",
    "            best_tags.reverse()\n",
    "            best_tags_list.append(best_tags)\n",
    "        return best_tags_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wARLMKuOKrxu"
   },
   "source": [
    "### 4. biLSTM_greedy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "ZW8Xigi3Krxu"
   },
   "outputs": [],
   "source": [
    "class  BiLSTM_greedy(nn.Module):\n",
    "    def __init__(self, input_dim, char_input_dim, output_dim, tgt_vocab, device, token_pad_idx, char_pad_idx, pretrained_weights):\n",
    "        super().__init__()\n",
    "        self.lstm = BiLSTM(input_dim, char_input_dim, output_dim, device, token_pad_idx, char_pad_idx, pretrained_weights)\n",
    "\n",
    "    \n",
    "    def neg_log_likelihood(self, src, row_src, tgt, lens):\n",
    "        \"\"\"Compute negative log likelihood given sentence and gold POS labels\"\"\"\n",
    "        feats = self.lstm(src, row_src, lens)  # torch.Size([5, 56, 47]); tgt.shape:torch.Size([5, 56])\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=TAG_PAD_IDX)\n",
    "        predictions = feats.view(-1, feats.shape[-1])\n",
    "        tags = tgt.view(-1)\n",
    "        loss = criterion(predictions, tags)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, src, row_src, lens):\n",
    "        \"\"\"Tag a single sentence\"\"\"\n",
    "        feats = self.lstm(src, row_src, lens)\n",
    "        return torch.argmax(feats, dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "y7t09aMqhnCs"
   },
   "outputs": [],
   "source": [
    "# seq_length = 3\n",
    "# lens = torch.tensor([3, 4, 5])\n",
    "# (torch.arange(seq_length).expand(lens.shape[0], seq_length) < lens.unsqueeze(1)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y38kMnOrKrxu"
   },
   "source": [
    "### 5. biLSTM_CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "553M9KcJCksN"
   },
   "outputs": [],
   "source": [
    "class  BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, input_dim, char_input_dim, output_dim, tgt_vocab, device, token_pad_idx, char_pad_idx, pretrained_weights):\n",
    "        super().__init__()\n",
    "        self.lstm = BiLSTM(input_dim, char_input_dim, output_dim, device, token_pad_idx, char_pad_idx, pretrained_weights)\n",
    "        self.crf = CRF(tgt_vocab, device=device)\n",
    "    \n",
    "    def neg_log_likelihood(self, src, row_src, tgt, lens):\n",
    "        \"\"\"Compute negative log likelihood given sentence and gold POS labels\"\"\"\n",
    "        feats = self.lstm(src, row_src, lens)\n",
    "        # print(feats.is_cuda)\n",
    "        forward_score = self.crf(feats, lens)\n",
    "        # print(f\"forward_score.is_cuda:{forward_score.is_cuda:}\")\n",
    "        gold_score = self.crf.score(feats, tgt, lens)\n",
    "        # print(f\"gold_score.is_cuda:{gold_score.is_cuda:}\")\n",
    "        return torch.sum(forward_score - gold_score)\n",
    "\n",
    "    def forward(self, src, row_src, lens):\n",
    "        \"\"\"Tag a single sentence\"\"\"\n",
    "        feats = self.lstm(src, row_src, lens)\n",
    "        out = self.crf.viterbi(feats, lens)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTf_WkREKrxv"
   },
   "source": [
    "## VII. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "4WcgTjaxDhgf"
   },
   "outputs": [],
   "source": [
    "input_dim = len(tokens)\n",
    "output_dim = len(tags)\n",
    "char_input_dim = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "PO_u2IjDDbVr"
   },
   "outputs": [],
   "source": [
    "# input_dim, char_input_dim, output_dim, tgt_vocab, device, token_pad_idx, char_pad_idx, pretrained_weights):\n",
    "model = BiLSTM_greedy(input_dim, char_input_dim, output_dim, tag_vocab, device, PAD_IDX, CHAR_PAD_IDX, weights_matrix)\n",
    "# model = BiLSTM_CRF(input_dim, char_input_dim, output_dim, tag_vocab, device, PAD_IDX, CHAR_PAD_IDX, weights_matrix)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "dkCEmgSiKrxv"
   },
   "outputs": [],
   "source": [
    "def eval_model(devset, model):\n",
    "    \"\"\"Given a development set and a model, compute the accuracy of the model prediction\n",
    "    on the development set\"\"\"\n",
    "    model.eval()\n",
    "    total_tokens = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        src, tgt, row_src, row_tgt, lens = next(iter(dev_dl))\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        lens = lens.to(device)\n",
    "    #             row_src = row_src.to(device)\n",
    "    #             row_tgt = row_tgt.to(device)\n",
    "\n",
    "        pred = model(src, row_src, lens)\n",
    "        for k in range(src.shape[0]):\n",
    "            length = lens[k]\n",
    "#             correct += (torch.tensor(pred[k]) == tgt[k, :length]).sum()\n",
    "            correct += (pred[k, :length] == tgt[k, :length]).sum()\n",
    "            # print(pred[k, :length])\n",
    "            # print(tgt[k, :length])\n",
    "            # print([idx2tag[tag.item()] for tag in pred[i, :length]])\n",
    "            # print([idx2tag[tag.item()] for tag in tgt[i, :length]])\n",
    "            total_tokens += length\n",
    "    dev_acc = correct/total_tokens\n",
    "    return dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIiQ73tEDg9V",
    "outputId": "b040422a-5fd2-4bbf-c78c-ed768a520291"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training 1/5]: 7969it [03:48, 34.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch # 1 Loss: 4258.29 Acc: 0.85\n",
      "Acc on dev: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training 2/5]: 7969it [04:29, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch # 2 Loss: 1943.03 Acc: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training 3/5]: 7969it [04:29, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch # 3 Loss: 1490.60 Acc: 0.94\n",
      "Acc on dev: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training 4/5]: 7969it [04:27, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch # 4 Loss: 1257.75 Acc: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training 5/5]: 7969it [04:24, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch # 5 Loss: 1117.18 Acc: 0.96\n",
      "Acc on dev: 0.95\n"
     ]
    }
   ],
   "source": [
    "do_validation = 2\n",
    "for i in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0.\n",
    "    num_correct = 0\n",
    "    num_tokens = 0\n",
    "\n",
    "    model.train()\n",
    "    for j, batch in tqdm.tqdm(enumerate(train_dl), desc=f'[Training {i+1}/{NUM_EPOCHS}]'):\n",
    "        src, tgt, row_src, row_tgt, lens = batch\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        lens = lens.to(device)\n",
    "        # row_src = row_src.to(device)\n",
    "        # row_tgt = row_tgt.to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        batch_size = src.shape[0]\n",
    "        \n",
    "        loss = model.neg_log_likelihood(src, row_src, tgt, lens)\n",
    "        epoch_loss += loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        pred = model(src, row_src, lens)\n",
    "        batch_size = src.shape[0]\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            length = lens[k]\n",
    "\n",
    "#             num_correct += (torch.tensor(pred[k]) == tgt[k, :length]).sum()\n",
    "            num_correct += (pred[k, :length] == tgt[k, :length]).sum()\n",
    "            num_tokens += length\n",
    "    epoch_acc = num_correct.item() / num_tokens\n",
    "    print(\"Training Epoch # {} Loss: {:.2f} Acc: {:.2f}\".format(i+1, epoch_loss.item(), epoch_acc))\n",
    "    \n",
    "\n",
    "    # validation on dev dataset\n",
    "    if i % do_validation == 0:\n",
    "    #     model.eval()\n",
    "    #     total_tokens = 0\n",
    "    #     correct = 0\n",
    "    #     with torch.no_grad():\n",
    "    #         src, tgt, row_src, row_tgt, lens = next(iter(dev_dl))\n",
    "    #         src = src.to(device)\n",
    "    #         tgt = tgt.to(device)\n",
    "    #         lens = lens.to(device)\n",
    "    # #             row_src = row_src.to(device)\n",
    "    # #             row_tgt = row_tgt.to(device)\n",
    "\n",
    "    #         pred = model(src, row_src, lens)\n",
    "    #         for k in range(src.shape[0]):\n",
    "    #             length = lens[k]\n",
    "    #             # correct += (torch.tensor(pred[k]).cuda() == tgt[k, :length]).sum()\n",
    "    #             correct += (pred[i, :length] == tgt[i, :length]).sum()\n",
    "    #             total_tokens += length\n",
    "    #     dev_acc = correct/total_tokens\n",
    "        # return correct/total_tokens\n",
    "        dev_acc = eval_model(next(iter(dev_dl)), model)\n",
    "        print(\"Acc on dev: {:.2f}\".format(dev_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qIjR0UmKrxv"
   },
   "source": [
    "## Testing on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGtyy2_-55TP",
    "outputId": "fd1bb2c5-7fb5-4646-a96e-361d5839d86d"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p6/w76xdd4n0gq5z_hcc7zglq2w0000gn/T/ipykernel_77990/3981862668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test/ptb_23.snt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_in_gold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# print(dev[:99])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p6/w76xdd4n0gq5z_hcc7zglq2w0000gn/T/ipykernel_77990/3935615645.py\u001b[0m in \u001b[0;36mread_in_gold_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p6/w76xdd4n0gq5z_hcc7zglq2w0000gn/T/ipykernel_77990/3935615645.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_in_plain_data(filename):\n",
    "    \"\"\"Read in plain text data for sequence labeling, assuming a one-sentence-per-line format\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.split() for line in lines]\n",
    "    return lines\n",
    "\n",
    "def featurize(line):\n",
    "    normalized_tokens = [x if x in token2idx else UNK for x in line]\n",
    "    featurized_tokens = [token2idx[x] for x in normalized_tokens]\n",
    "    return featurized_tokens\n",
    "\n",
    "def padding(data):\n",
    "    featurized_lines = []\n",
    "    for line in data:\n",
    "        featurized_lines.append(torch.tensor(featurize(line), dtype=torch.int64))\n",
    "    lens = [len(x) for x in featurized_lines]\n",
    "#     print(featurized_lines)\n",
    "    tokens = pad_sequence(featurized_lines, batch_first=True, padding_value=PAD_IDX)\n",
    "    return tokens, torch.tensor(lens)\n",
    "\n",
    "\n",
    "test_filepath = os.path.join(os.getcwd(), \"dev/ptb_23.snt\")\n",
    "dev = read_in_gold_data(test_filepath)\n",
    "print(dev)\n",
    "# print(dev[:99])\n",
    "gold = [tag for seq, tag in dev]\n",
    "# print(gold[:99])\n",
    "\n",
    "\n",
    "# test_filepath = \"/content/drive/MyDrive/PA3_Starter_code/dev/ptb_22.snt\"\n",
    "test_filepath = os.path.join(os.getcwd(), \"dev/ptb_22.snt\")\n",
    "data = read_in_plain_data(test_filepath)\n",
    "tokens, lens = padding(data)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#   pred = model(tokens.to(device), data, lens.to(device))\n",
    "# print(len(pred))\n",
    "# print(idx2tag)\n",
    "# for line in pred:\n",
    "#     print([idx2tag[tag] for tag in line])\n",
    "# return correct/total_tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbEYNBRpKrxw",
    "outputId": "d822756a-80fb-49c5-9c6f-84166c12a355"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor(16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p6/w76xdd4n0gq5z_hcc7zglq2w0000gn/T/ipykernel_77990/2148867380.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# print(gol)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_tagseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# print(cnt, cor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p6/w76xdd4n0gq5z_hcc7zglq2w0000gn/T/ipykernel_77990/2148867380.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# print(gol)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_tagseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# print(cnt, cor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: tensor(16)"
     ]
    }
   ],
   "source": [
    "def compare_tagseq(goldseq, predicted_seq):\n",
    "    \"\"\"Compare two sequences and output the length of the sequence \n",
    "    and the number of tags they share. A helper function to the evaluation function\"\"\"\n",
    "    pairs = zip(goldseq, predicted_seq)\n",
    "    correct = len([1 for pair in pairs if pair[0]== pair[1]])\n",
    "    return len(goldseq), correct\n",
    "\n",
    "    \n",
    "i = 0\n",
    "total = 0\n",
    "correct = 0\n",
    "for tags, line, gol in zip(pred, data, gold):\n",
    "    i += 1\n",
    "    # print(gol)\n",
    "    # for tag in tags:\n",
    "    #   print(tag)\n",
    "    #   print()\n",
    "    # print([idx2tag[tag.item()] for tag in tags])\n",
    "    # print(line)\n",
    "    # print(gol)\n",
    "    cnt, cor = compare_tagseq(gol, [idx2tag[tag] for tag in tags])\n",
    "    # print(cnt, cor)\n",
    "    total += cnt\n",
    "    correct += cor\n",
    "    # print(line)\n",
    "    # print([idx2tag[tag] for tag in tags])\n",
    "    # print(gol)\n",
    "    # print()\n",
    "    # if i == 99:\n",
    "    #   break\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "KI28r03-Krxw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dev_result = [1, 2, 3, 4, 5]\n",
    "dev_result2 = [2, 3, 4, 5, 6]\n",
    "plt.figure()\n",
    "plt.plot(list(range(NUM_EPOCHS)), dev_result, 'b', label='random initialized embeddings')\n",
    "plt.plot(list(range(NUM_EPOCHS)), dev_result2, 'g', label='pre-training embeddings')\n",
    "plt.title('validation acc on different epoches')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "project3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
